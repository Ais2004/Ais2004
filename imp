import pandas as pd
import pickle
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.metrics import mean_absolute_error, r2_score

# Import Regression Models
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor

# Load dataset
df = pd.read_csv("train_speed_data.csv")

# Features & Target Variable
X = df.drop(columns=["Recommended_Speed"])
y = df["Recommended_Speed"]

# Identify categorical and numerical features
categorical_features = ["Track_Condition", "Weather"]
numerical_features = ["Current_Speed", "Obstacle_Detected", "Station_Proximity"]

# Preprocessing: One-Hot Encoding for categorical features and Scaling for numerical features
preprocessor = ColumnTransformer(
    transformers=[
        ("cat", OneHotEncoder(handle_unknown="ignore"), categorical_features),
        ("num", StandardScaler(), numerical_features),
    ]
)

# Define different models
models = {
    "Linear Regression": LinearRegression(),
    "Decision Tree": DecisionTreeRegressor(random_state=42),
    "Random Forest": RandomForestRegressor(n_estimators=100, random_state=42),
    "Gradient Boosting": GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
}

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Dictionary to store model results
model_results = {}

# Train and evaluate each model
for name, model in models.items():
    # Create a pipeline with preprocessing and model
    pipeline = Pipeline([
        ("preprocessor", preprocessor),
        ("regressor", model)
    ])
    
    # Train the model
    pipeline.fit(X_train, y_train)
    
    # Make predictions
    y_pred = pipeline.predict(X_test)
    
    # Evaluate the model
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    
    # Store results
    model_results[name] = {"MAE": mae, "R¬≤ Score": r2}
    
    print(f"‚úÖ {name} - MAE: {mae:.3f}, R¬≤ Score: {r2:.3f}")

# Find the best model based on MAE
best_model_name = min(model_results, key=lambda k: model_results[k]["MAE"])
best_model = models[best_model_name]

# Save the best model
final_pipeline = Pipeline([
    ("preprocessor", preprocessor),
    ("regressor", best_model)
])
final_pipeline.fit(X_train, y_train)

with open("best_train_speed_model.pkl", "wb") as file:
    pickle.dump(final_pipeline, file)

print(f"\nüèÜ Best Model: {best_model_name} (Saved as best_train_speed_model.pkl)")
